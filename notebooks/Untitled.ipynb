{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "715205b7-a654-47aa-bd38-722212dc2021",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetworks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m define_G, DeeperWiderConvAutoencoder2D\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EEGfMRIDataset\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SSIMLoss\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from models.networks import define_G, DeeperWiderConvAutoencoder2D\n",
    "from data.datasets import EEGfMRIDataset\n",
    "from models.losses import SSIMLoss\n",
    "import torchmetrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "\n",
    "# Argument parsing\n",
    "parser = argparse.ArgumentParser(description=\"EEG to fMRI Autoencoder Training Script\")\n",
    "parser.add_argument('--dataset_name', type=str, default=\"01\", help=\"Dataset identifier\")\n",
    "parser.add_argument('--data_root', type=str, default=\"/groups/1/gca50041/quan/Datasets/EEG2fMRI/h5_data/NODDI\", \n",
    "                    help=\"Path to the dataset directory in h5 format\")\n",
    "parser.add_argument('--work_dir', type=str, default=\"/scratch/1/acb11155on/WorkSpace/eeg2fmri\", help=\"Path to save experiments\")\n",
    "\n",
    "parser.add_argument('--num_epochs', type=int, default=300, help=\"Number of epochs for training\")\n",
    "parser.add_argument('--batch_size', type=int, default=64, help=\"Batch size for training and testing\")\n",
    "parser.add_argument('--lr', type=float, default=1e-3, help=\"Learning rate for optimizer\")\n",
    "parser.add_argument('--weight_decay', type=float, default=0.01, help=\"Weight decay for optimizer\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # W&B\n",
    "# wandb.login()\n",
    "\n",
    "def plot_comparison(labels, outputs, slice_idx=16):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    label_slice = labels[0, slice_idx, :, :]\n",
    "    output_slice = outputs[0, slice_idx, :, :]\n",
    "    diff_slice = np.abs(label_slice - output_slice)\n",
    "\n",
    "    axes[0].imshow(label_slice, cmap='gray')\n",
    "    axes[0].set_title('Ground Truth')\n",
    "\n",
    "    axes[1].imshow(output_slice, cmap='gray')\n",
    "    axes[1].set_title('Generated Output')\n",
    "\n",
    "    axes[2].imshow(diff_slice, cmap='gray')\n",
    "    axes[2].set_title('Difference')\n",
    "    \n",
    "    buff = BytesIO()\n",
    "    plt.savefig(buff, format='png')\n",
    "    buff.seek(0)\n",
    "    # Convert the BytesIO object to an Image object\n",
    "    image = Image.open(buff)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    return image\n",
    "\n",
    "# Normalize data\n",
    "def normalize_data(data: np.ndarray, scale_range: Tuple=None):\n",
    "    \"\"\"Normalize data to range [a, b]\"\"\"\n",
    "    # scale to range [0, 1] first\n",
    "    new_data = (data - data.min())/(data.max() - data.min())\n",
    "    # scale to range [a, b]\n",
    "    if scale_range is not None:\n",
    "        a, b = scale_range\n",
    "        assert a<=b, f'Invalid range: {scale_range}'\n",
    "        new_data = (b-a)*new_data + a\n",
    "\n",
    "    return new_data\n",
    "\n",
    "# PSNR Calculation\n",
    "def calculate_psnr(img1, img2):\n",
    "    mse = nn.functional.mse_loss(img1, img2)\n",
    "    psnr = 20 * torch.log10(1.0 / torch.sqrt(mse))\n",
    "    return psnr.item()\n",
    "\n",
    "def load_h5_from_list(data_root: str, individual_list: List):\n",
    "    eeg_data = None\n",
    "    fmri_data = None\n",
    "\n",
    "    pbar = tqdm(individual_list, leave=True)\n",
    "    for individual_name in pbar:\n",
    "        pbar.set_description(f'Individual {individual_name}')\n",
    "        with h5py.File(Path(data_root)/f'{individual_name}.h5', 'r') as f:\n",
    "            eeg_indv = np.array(f['eeg'][:])\n",
    "            fmri_indv = np.array(f['fmri'][:])\n",
    "\n",
    "            eeg_data = eeg_indv if eeg_data is None else np.concatenate([eeg_data, eeg_indv], axis=0)\n",
    "            fmri_data = fmri_indv if fmri_data is None else np.concatenate([fmri_data, fmri_indv], axis=0)\n",
    "    \n",
    "    return eeg_data, fmri_data\n",
    "\n",
    "\"\"\"Load the data\n",
    "Data is already in zero-mean and unit-std\n",
    "\"\"\"\n",
    "# NOTE: config list of train/test\n",
    "# # Train/test from David\n",
    "# train_list = ['32', '35', '36', '37', '38', '39', '40', '42']\n",
    "# test_list = ['43', '44']\n",
    "\n",
    "# Train/test Quan-Kris\n",
    "test_list = ['43', '44']\n",
    "train_list = [Path(indv).stem for indv in os.listdir(args.data_root) if Path(indv).stem not in test_list]\n",
    "\n",
    "print(sorted(train_list))\n",
    "\n",
    "# each data has: [N_sample, H, W, C]\n",
    "print(f'Loading train data ...')\n",
    "eeg_train, fmri_train = load_h5_from_list(args.data_root, individual_list=train_list)\n",
    "print(f'Loading test data ...')\n",
    "eeg_test, fmri_test = load_h5_from_list(args.data_root, individual_list=test_list)\n",
    "\n",
    "# In PyTorch, 1 data sample is represented as [C, H, W]\n",
    "eeg_train = eeg_train.transpose(0, 3, 1, 2)\n",
    "fmri_train = fmri_train.transpose(0, 3, 1, 2)\n",
    "\n",
    "eeg_test = eeg_test.transpose(0, 3, 1, 2)\n",
    "fmri_test = fmri_test.transpose(0, 3, 1, 2)\n",
    "\n",
    "# Normalize the data to range [a, b]\n",
    "# NOTE: this is optional, we ONLY can choose either zero-mean unit-std scale OR [a, b] scale\n",
    "eeg_train = normalize_data(eeg_train, scale_range=(0, 1))\n",
    "fmri_train = normalize_data(fmri_train, scale_range=(0, 1))\n",
    "\n",
    "eeg_test = normalize_data(eeg_test, scale_range=(0, 1))\n",
    "fmri_test = normalize_data(fmri_test, scale_range=(0, 1))\n",
    "\n",
    "print(\"EEG Train Shape:\", eeg_train.shape)\n",
    "print(\"fMRI Train Shape:\", fmri_train.shape)\n",
    "print(\"EEG Test Shape:\", eeg_test.shape)\n",
    "print(\"fMRI Test Shape:\", fmri_test.shape)\n",
    "\n",
    "train_dataset = EEGfMRIDataset(eeg_data=torch.tensor(eeg_train, dtype=torch.float32), \n",
    "                               fmri_data=torch.tensor(fmri_train, dtype=torch.float32))\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = EEGfMRIDataset(eeg_data=torch.tensor(eeg_test, dtype=torch.float32), \n",
    "                              fmri_data=torch.tensor(fmri_test, dtype=torch.float32))\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "# Initialize a new W&B run with the current timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "exp_name = f\"dataset_{args.dataset_name}_run_{timestamp}\"\n",
    "\n",
    "exp_dir = os.path.join(args.work_dir, exp_name)\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "run = wandb.init(project=\"eeg_fmri_project\", name=exp_name)\n",
    "\n",
    "# Initialize the model, eeg: [H, W, 10], fmri: [H, W, 30]\n",
    "# model = define_G(input_nc=10, output_nc=30, ngf=64, netG='resnet_3blocks', output_size=64).to(device)\n",
    "model = DeeperWiderConvAutoencoder2D(input_nc=10, output_nc=30, output_size=64).to(device)\n",
    "\n",
    "# # Kris's original code\n",
    "# model = DeeperWiderConvAutoencoder3D().to(device)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = SSIMLoss().to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "# Training loop with timing and SSIM tracking\n",
    "total_training_time = 0.0\n",
    "best_ssim = -1.0\n",
    "best_psnr = -1.0\n",
    "best_model_weights = None\n",
    "best_save_path = None\n",
    "\n",
    "pbar = tqdm(range(args.num_epochs), leave=True)\n",
    "\n",
    "calculate_ssim = torchmetrics.image.StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
    "\n",
    "for epoch in pbar:\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # labels = labels.permute(0, 4, 1, 2, 3)[:, :, :, :, :28]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    scheduler.step(epoch_loss)\n",
    "\n",
    "    # track the latest lr\n",
    "    last_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "    total_training_time += epoch_duration\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    ssim_score = 0.0\n",
    "    psnr_score = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # labels = labels.permute(0, 4, 1, 2, 3)[:, :, :, :, :28]\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            ssim_score += calculate_ssim(outputs, labels).item()\n",
    "            psnr_score += calculate_psnr(outputs, labels)\n",
    "\n",
    "    ssim_score /= len(test_loader)\n",
    "    psnr_score /= len(test_loader)\n",
    "\n",
    "    # visualize the last batch\n",
    "    labels_np = labels.cpu().numpy()\n",
    "    outputs_np = outputs.cpu().numpy()\n",
    "    image = plot_comparison(labels_np, outputs_np, slice_idx=16)\n",
    "\n",
    "    run.log({\n",
    "        \"lr\": last_lr,\n",
    "        \"loss\": epoch_loss,\n",
    "        \"ssim\": ssim_score,\n",
    "        \"psnr\": psnr_score,\n",
    "        \"image\": wandb.Image(image),\n",
    "    })\n",
    "\n",
    "    if ssim_score > best_ssim:\n",
    "        best_ssim = ssim_score\n",
    "        best_psnr = psnr_score\n",
    "        # remove the latest model\n",
    "        if best_save_path is not None:\n",
    "            os.remove(best_save_path)\n",
    "        # Save the best model weights with SSIM and PSNR scores in the filename\n",
    "        best_save_path = os.path.join(exp_dir, f\"epoch{epoch}_ssim_{best_ssim:.4f}_psnr_{best_psnr:.2f}.pth\")\n",
    "        torch.save(model.state_dict(), best_save_path)\n",
    "    \n",
    "    pbar.set_description(f'SSIM: {ssim_score:.3f} / PSNR: {psnr_score:.3f} / Loss: {epoch_loss:.3f} / Best SSIM: {best_ssim:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
